{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "49a68a29-8ab5-4580-b7d4-baae65bdbda3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "        .master('local[*]')\\\n",
    "        .appName('test') \\\n",
    "        .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d5886d3-5609-47c9-a23e-126dfbcf1f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_green = spark.read.parquet('data/pq/green/*/*')\n",
    "df_yellow = spark.read.parquet(\"data/pq/yellow/*/*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97dbdab4-a3f5-44b7-94ea-d30242f4b12f",
   "metadata": {},
   "outputs": [],
   "source": [
    "common_cols = []\n",
    "yellow_cols = set(df_yellow.columns)\n",
    "\n",
    "for col in df_green.columns:\n",
    "    if col in yellow_cols:\n",
    "        common_cols.append(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c86f7219-c03e-4a74-9e19-405a43c6db1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as funcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85bd07c1-0e96-4d5e-9fa0-5d2ac56c7d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_green_sel = df_green.select(common_cols)\n",
    "df_yellow_sel = df_yellow.select(common_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d253f0bb-c9fa-4681-a48c-04fb12c9fbca",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trips_data = df_green_sel.unionAll(df_yellow_sel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "468b88b1-b389-4b11-9beb-2ff079d1c816",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results = spark.sql(\"\"\"\n",
    "SELECT  \n",
    "    -- Revenue grouping \n",
    "    date_trunc('month', 'pickup_datetime') as revenue_month, \n",
    "\n",
    "    service_type, \n",
    "\n",
    "    -- Revenue calculation \n",
    "    SUM(fare_amount) as revenue_monthly_fare,\n",
    "    SUM(extra) as revenue_monthly_extra,\n",
    "    SUM(mta_tax) as revenue_monthly_mta_tax,\n",
    "    SUM(tip_amount) as revenue_monthly_tip_amount,\n",
    "    SUM(tolls_amount) as revenue_monthly_tolls_amount,\n",
    "    SUM(improvement_surcharge) as revenue_monthly_improvement_surcharge,\n",
    "    SUM(total_amount) as revenue_monthly_total_amount,\n",
    "\n",
    "    -- Additional calculations\n",
    "    AVG(passenger_count) as avg_monthly_passenger_count,\n",
    "    AVG(trip_distance) as avg_monthly_trip_distance\n",
    "\n",
    "FROM trips_data\n",
    "    GROUP BY revenue_month, service_type\n",
    "\n",
    "        \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9df6a49b-00fe-4b5d-8142-8261ffad6b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "294b23ea-aaa2-4671-9045-b15564368547",
   "metadata": {},
   "outputs": [],
   "source": [
    "YELLOW_SCHEMA = types.StructType([\n",
    "    types.StructField(\"VendorID\", types.IntegerType(), True),\n",
    "    types.StructField(\"tpep_pickup_datetime\", types.TimestampType(), True),\n",
    "    types.StructField(\"tpep_dropoff_datetime\", types.TimestampType(), True),\n",
    "    types.StructField(\"passenger_count\", types.IntegerType(), True),\n",
    "    types.StructField(\"trip_distance\", types.DoubleType(), True),\n",
    "    types.StructField(\"RatecodeID\", types.IntegerType(), True),\n",
    "    types.StructField(\"store_and_fwd_flag\", types.StringType(), True),\n",
    "    types.StructField(\"PULocationID\", types.IntegerType(), True),\n",
    "    types.StructField(\"DOLocationID\", types.IntegerType(), True),\n",
    "    types.StructField(\"payment_type\", types.IntegerType(), True),\n",
    "    types.StructField(\"fare_amount\", types.DoubleType(), True),\n",
    "    types.StructField(\"extra\", types.DoubleType(), True),\n",
    "    types.StructField(\"mta_tax\", types.DoubleType(), True),\n",
    "    types.StructField(\"tip_amount\", types.DoubleType(), True),\n",
    "    types.StructField(\"tolls_amount\", types.DoubleType(), True),\n",
    "    types.StructField(\"improvement_surcharge\", types.DoubleType(), True),\n",
    "    types.StructField(\"total_amount\", types.DoubleType(), True),\n",
    "    types.StructField(\"congestion_surcharge\", types.DoubleType(), True)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5d661be0-e768-4f33-b08f-d0ba4d610a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.parquet('yellow_tripdata_2023-12.parquet', schema = YELLOW_SCHEMA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7793f121-50b7-4616-b68b-9490e07edbbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import types \n",
    "from pyspark.sql.functions import md5, concat_ws, col, coalesce, concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bc7e1e6e-63cf-4837-b863-4b994ecd7458",
   "metadata": {},
   "outputs": [
    {
     "ename": "AnalysisException",
     "evalue": "Column '``' does not exist. Did you mean one of the following? [extra, mta_tax, VendorID, RatecodeID, tip_amount, Airport_fee, fare_amount, DOLocationID, PULocationID, payment_type, tolls_amount, total_amount, trip_distance, passenger_count, store_and_fwd_flag, congestion_surcharge, tpep_pickup_datetime, improvement_surcharge, tpep_dropoff_datetime];\n'Project [VendorID#97, tpep_pickup_datetime#98, tpep_dropoff_datetime#99, passenger_count#100L, trip_distance#101, RatecodeID#102L, store_and_fwd_flag#103, PULocationID#104, DOLocationID#105, payment_type#106L, fare_amount#107, extra#108, mta_tax#109, tip_amount#110, tolls_amount#111, improvement_surcharge#112, total_amount#113, congestion_surcharge#114, Airport_fee#115, md5(concat(coalesce(cast(VendorID#97 as string), '), coalesce(cast('pickup_datetime as string), '), coalesce(cast('dropoff_datetime as string), '), coalesce(cast(PULocationID#104 as string), '), coalesce(cast(DOLocationID#105 as string), '), coalesce(cast(fare_amount#107 as string), '), coalesce(cast(trip_distance#101 as string), '))) AS unique_row_id#137]\n+- Relation [VendorID#97,tpep_pickup_datetime#98,tpep_dropoff_datetime#99,passenger_count#100L,trip_distance#101,RatecodeID#102L,store_and_fwd_flag#103,PULocationID#104,DOLocationID#105,payment_type#106L,fare_amount#107,extra#108,mta_tax#109,tip_amount#110,tolls_amount#111,improvement_surcharge#112,total_amount#113,congestion_surcharge#114,Airport_fee#115] parquet\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mwithColumn(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munique_row_id\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      2\u001b[0m                                 md5(\n\u001b[1;32m      3\u001b[0m                                 concat(  \u001b[38;5;66;03m# Concatenate without a separator\u001b[39;00m\n\u001b[1;32m      4\u001b[0m                                 coalesce(col(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mVendorID\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mcast(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstring\u001b[39m\u001b[38;5;124m\"\u001b[39m), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m      5\u001b[0m                                 coalesce(col(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpickup_datetime\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mcast(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstring\u001b[39m\u001b[38;5;124m\"\u001b[39m), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m      6\u001b[0m                                 coalesce(col(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdropoff_datetime\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mcast(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstring\u001b[39m\u001b[38;5;124m\"\u001b[39m), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m      7\u001b[0m                                 coalesce(col(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPULocationID\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mcast(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstring\u001b[39m\u001b[38;5;124m\"\u001b[39m), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m      8\u001b[0m                                 coalesce(col(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDOLocationID\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mcast(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstring\u001b[39m\u001b[38;5;124m\"\u001b[39m), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m      9\u001b[0m                                 coalesce(col(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfare_amount\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mcast(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstring\u001b[39m\u001b[38;5;124m\"\u001b[39m), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m     10\u001b[0m                                 coalesce(col(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrip_distance\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mcast(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstring\u001b[39m\u001b[38;5;124m\"\u001b[39m), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     11\u001b[0m                                 )\n\u001b[1;32m     12\u001b[0m                         )\n\u001b[1;32m     13\u001b[0m                         )\n",
      "File \u001b[0;32m~/spark/spark-3.3.2-bin-hadoop3/python/pyspark/sql/dataframe.py:3036\u001b[0m, in \u001b[0;36mDataFrame.withColumn\u001b[0;34m(self, colName, col)\u001b[0m\n\u001b[1;32m   3034\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(col, Column):\n\u001b[1;32m   3035\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcol should be Column\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 3036\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m DataFrame(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jdf\u001b[38;5;241m.\u001b[39mwithColumn(colName, col\u001b[38;5;241m.\u001b[39m_jc), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msparkSession)\n",
      "File \u001b[0;32m~/spark/spark-3.3.2-bin-hadoop3/python/lib/py4j-0.10.9.5-src.zip/py4j/java_gateway.py:1321\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1315\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1316\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1320\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1321\u001b[0m return_value \u001b[38;5;241m=\u001b[39m get_return_value(\n\u001b[1;32m   1322\u001b[0m     answer, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_id, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname)\n\u001b[1;32m   1324\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[1;32m   1325\u001b[0m     temp_arg\u001b[38;5;241m.\u001b[39m_detach()\n",
      "File \u001b[0;32m~/spark/spark-3.3.2-bin-hadoop3/python/pyspark/sql/utils.py:196\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    192\u001b[0m converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n\u001b[1;32m    193\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(converted, UnknownException):\n\u001b[1;32m    194\u001b[0m     \u001b[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001b[39;00m\n\u001b[1;32m    195\u001b[0m     \u001b[38;5;66;03m# JVM exception message.\u001b[39;00m\n\u001b[0;32m--> 196\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m converted \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    197\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    198\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[0;31mAnalysisException\u001b[0m: Column '``' does not exist. Did you mean one of the following? [extra, mta_tax, VendorID, RatecodeID, tip_amount, Airport_fee, fare_amount, DOLocationID, PULocationID, payment_type, tolls_amount, total_amount, trip_distance, passenger_count, store_and_fwd_flag, congestion_surcharge, tpep_pickup_datetime, improvement_surcharge, tpep_dropoff_datetime];\n'Project [VendorID#97, tpep_pickup_datetime#98, tpep_dropoff_datetime#99, passenger_count#100L, trip_distance#101, RatecodeID#102L, store_and_fwd_flag#103, PULocationID#104, DOLocationID#105, payment_type#106L, fare_amount#107, extra#108, mta_tax#109, tip_amount#110, tolls_amount#111, improvement_surcharge#112, total_amount#113, congestion_surcharge#114, Airport_fee#115, md5(concat(coalesce(cast(VendorID#97 as string), '), coalesce(cast('pickup_datetime as string), '), coalesce(cast('dropoff_datetime as string), '), coalesce(cast(PULocationID#104 as string), '), coalesce(cast(DOLocationID#105 as string), '), coalesce(cast(fare_amount#107 as string), '), coalesce(cast(trip_distance#101 as string), '))) AS unique_row_id#137]\n+- Relation [VendorID#97,tpep_pickup_datetime#98,tpep_dropoff_datetime#99,passenger_count#100L,trip_distance#101,RatecodeID#102L,store_and_fwd_flag#103,PULocationID#104,DOLocationID#105,payment_type#106L,fare_amount#107,extra#108,mta_tax#109,tip_amount#110,tolls_amount#111,improvement_surcharge#112,total_amount#113,congestion_surcharge#114,Airport_fee#115] parquet\n"
     ]
    }
   ],
   "source": [
    "df = df.withColumn(\"unique_row_id\",\n",
    "                                md5(\n",
    "                                concat(  # Concatenate without a separator\n",
    "                                coalesce(col(\"VendorID\").cast(\"string\"), \"\"),\n",
    "                                coalesce(col(\"tpep_pickup_datetime\").cast(\"string\"), \"\"),\n",
    "                                coalesce(col(\"tpep_dropoff_datetime\").cast(\"string\"), \"\"),\n",
    "                                coalesce(col(\"PULocationID\").cast(\"string\"), \"\"),\n",
    "                                coalesce(col(\"DOLocationID\").cast(\"string\"), \"\"),\n",
    "                                coalesce(col(\"fare_amount\").cast(\"string\"), \"\"),\n",
    "                                coalesce(col(\"trip_distance\").cast(\"string\"), \"\")\n",
    "                                )\n",
    "                        )\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d98be3-e68a-407d-89ed-4f8a4ac5d87e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
